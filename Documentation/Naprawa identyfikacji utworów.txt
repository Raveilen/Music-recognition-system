Naprawa identyfikacji utworów (co wziąć pod uwagę)?

	- Zastanowić się czy przedziały częstotliwości dobrane są prawidłowo (powinny być peaki częstoliwości w obrębie chunka - powinny tworzyć nam hasza dla piosenki).
	x Zmiana Samplowania utworów niestety nic nie dała (dalej nie wykrywa utworów z nagrania)
	- można spróbować zaimplementować rozwiązanie ze spektrogramem zamiast haszowania takiego jakie mam obecnie
	-
	
	
Potencjalne problemy:
	
	Hasze wyraźnie są różne dla dźwięku nagranego i dla dźwięku z mp3
	
	1) Mikrofon nie nagrywa prawidłowo dźwięku
		A Przygotować prosty program do odtworzenia nagranego dźwięku (zobaczyć co faktycznie przychodzi na input) FAILED (aczkolwiek dźwięk jest cichszy)
			Dźwięk wydaje się być odpowiedni aczkolwiek jest dużo cichszy niż dźwięk dostarczony w nagraniu mp3
		
	2) Przetwarzanied dźwięku z mikrofonu odbywa się inczej niż przetwarzanie z mp3 (stąd inne hasze)
		A Ujednolicić formaty dźwięku FAILED
		!B Zmienić metodę tworzenia haszy (np. spektrogramy) (np. rozwiązanie zapropnowane przez czat)
		C Zmniejszyć rozmiar chunka (być może peak dobierany jest na zbyt dużym obszarze stąd ciężko o dobre przypasowanie) (RACZEJ NIE O TO CHODZI)
			Rozmiar chunka wpływa na dokładność, mniejszy chunk to większa dokładnośc czasowa, ale mniejsza dokładność jeśli chodzi o znajdowane peaki.
		D Przeanalizować Proces generowania hasza dla obu przypadków 
		E Zastosować zazebianie się haszy SLIGHTLY BETTER
			Zaimplementowano zazębianie się haszy w stopniu 50%
			Niestety nie ma zbyt dużej poprawy
		
	3) Przedział z którego wybieramy wartości dla hasza nie wystarczająco miarodanjny aby rozpoznać piosenkę
	
	Dla Overlaping 50% bedziemy mieli 2* CHUNK_COUNT  - 1 okienek do ogarnięcia
	

Dziennik
13.01.2025
Jeżeli nie pomoże rozwiązanie ze zazębianiem, należy spróbować rozwiązać generowanie spektrogramami tak jak zalecił to czat.
W ten sposób być może faktycznie nie będzie problemu z różnicą w generowanych haszach
Szczególnie zwrócić uwagę na przedział w którym generowane są hasze (w jaki sposób następuje segregacja które przedziały faktycznie uwzględniamy w haszowaniu)

Warto się też może zastanowić, skoro ograniczamy ilość generowanych haszy, to może by tak generować tylko częstotliwości które wykorzystamy

Dodanie zazębiania się sprawiło że mamy więcej haszy (niemalże dwukrotnie) na piosenkę

Niestety, algorytm dalej praktycznie nie jest w stanie rozpoznać piosenki.

Prawdopodobnie problem leży zakorzeniony w samym algorytmie tworzenia haszy lub wykrywania peaków. KIERUNEK ROZWOJU

Przed przystąpieniem do pracy, zapisać wersję programu na githubie (ogarnąć system kontroli wersji)

TO DO:
	- przeładować nagrania
	- ogarnąć system kontroli wersji
	- spróbować zastosować implementację haszy w oparciu o wskazówki z czata gpt (być może rozwiązanie ze spektrogramami sprawdzi się lepiej przy identyfikacji)
	- zostawić na wszelki wypadek przerobioną, dotychczasową wersję programu jakby trzeba było wrócić do rozwiązania z artykułu.
	- Sprawdzić rezultaty dla tak zorganiozwanego haszowania
	- Jeśli to nie pomoże, szukamy innego rozwiązania tworzenia haszy (przegląd literatury)

PRO TIP
Można znaleźć sobie krótsze dźwięki do identyfikacji żeby trochę krócej się to wszystko przetwarzało (a przynajmniej dopóki nie ogarnę rozsądnego haszowania) DONE

Dziennik 14.01.2025
Szukanie piosenek z tekstem idzie nieco lepiej niż szukanie piosenek z samą melodią, ale i tak wynik jest raczej mizerny RESULT

Przebudować na koniec projektowania wariantu spektrogramowego konstruktury w SongProcessor aby nie było takiego zróżnicowania pomiędzy nagraniem a normalnym dźwiękiem.

Zamiast AudioData lepiej będzie zastosować pole byte[] do przetwarzania

Jeżeli Rozwiązanie ze spektrogramem okaże sie skuteczne, to konieczne będzie szczegółowe doczytanie o oknie, Hamminga, jego zastosowaniu a także czym faktycznie ono jest (znaleźć literaturę do tego)

Okno Hamminga pozwala na oczyszczenie krańców okien z niepotrzebnych zakłóceń (w dużym skrócie)

Rozważyć, w celu zwiększenia wydajności programu, zastosowanie operacji LINQ zamiast pętli (podobnie jak w pythonie redukujemy ręczne iteracje, to nie C)

W podeściu ze spektrogramami (ale chyba nie tylko), domenę czasu wyznaczają nam okna natomiast domenę częstotliwości, poszczególne wartości magnitue w danym oknie.
Generalnie jeśli o to chodzi to spektrogram przechowuje zlogarytmizowane wartości magnitue, które wiemy w jakich momentach czasowych się znajdują dzięki podziałowi na okna.
		

I'm not sure about one thing. What about song sequences which overlaps within a song. If we construct hash based on frequencies and time differences between peaks

Generalnie po zastosowaniu skali logarytminczej sugeruje że większość db to [-40, 0] (poniżej -40 są już dźwięki ciche).
Wartości db mogą sięgać jednak nawet 40 a w Alanie Jacksonie 50db

ROZKMINIĆ DLACZEGO POWTARZAJĄ SIĘ TIMESTAMPY

Generowanie haszy odbywa się nie najgorzej, aczkolwiek jest ich zdecydowanie za dużo. Można pobawić się thresholdem, ale nie dla każdej piosenki będzie to rozwiązanie korzystne.

To do:
	- Spróbować przegenerować dla większego thresholda
	- Spróbować połączyć podejścia z zapisywaniem wartości największych i odległościami między peakami
	- Przepatrzeć dokładnie jeszcze raz kod na czacie i porównać rozwiązania (być może coś mi umknęło lub zostało źle zaimplementowane)
	- Rozwiązać problem zduplikowanych timestampów (dlaczego część wartości jest identyczna) - chyba nie powinno tak być
	- sprawdzić jakie są inne możeliwości (poza tresholdem i min max) żeby otwfiltrować nadmierne hasze i jednocześnie zapewnić sporą dokładność rozpoznawania
		- zaimplementować inny sposób ograniczania liczby haszy na przedział na podstawie wylistowanych metod (wybrać którąś i przetestować)
		Fajne:
			- Top N peaks
			- Frequency band limiting (dzielimy sobie na obszary częstotliwości i na ich podstawie określamy ile maksymalnych wartości chcemy - łączenie z Top n peaks)
			- NMS - sprawdzamy sąsiedztwo i wybieramy tylko peaki w obrębie danego sąsiedztwa
			- adaptive thresholding - dopasowuje peaki na podstawie wartości w chunku a nie na podstawie odgórnie narzuconego thresholdu
	
	Częściowo udało się przegenerować hasze dla pierwszego utworu, należy dostosować nagrywanie pod to i sparawdzić czy znajdowane będą prawidłowo piosenki przy znacząco zwiększonej liczbie haszy.
	
Dziennik 15.01.2025
Spektrogram z chunka z nagrania charakteryzuje się tym, że mamy do czynienia ze znacznie mniejszą ilością. Mimo że dźwięk jest stosunkowo głośno, to ilość decybeli w spektrogramie sięga +- [-100, -50]db.

Dźwięk w uzyskany z nagrania (Blues Saraceno) charakteryzuje się tym że dopiero około 7800 bajata zaczyna coś reprezentować (nie wynosi 0), ale zwykle jest to przeplatane wartościami skrajnymi (około 255, 253 itp.) także zakładam że to może być szum. Pojawiają się również wartości 0-10 (czyli szum z tej drugiej strony)

Od około 8100 bajta piosenka zaczyna się powoli rozkręcać a wartości coraz bardziej zbliżają się do środka przedziału.

Dopiero od 3 chunka można powiedzieć że w wersji przetworzonej z pliku pojawiają się decybele przekraczające 0. W pierwszym i drugim chunku tylko wartości -120db. Dopiero w 3 chunku pojawiają się inne ujemne wartości decybeli ale już nie -120. (Moment w którym rozkręca się piosenka)

W przypadku spektrogramów z nagrania wartości decybeli wahają się od -70 do -50db około

W dalszych częściach utworu wartości wydają się być bardziej zbliżone do 0 a czasami są nawet dodatnie, nie mniej jednak średnia wartości oscyluje zdecydowanie w przedziale -60 do -30db (czyli ujemne).

To tłumaczy dla czego nie są generowane żadne matche (threshold powyżej 20db, a tutaj po prostu prawdopodobnie nie ma takich wartości, albo występują bardzo sporadycznie).

Generalnie zatem wygląda na to że przedział decybeli dla nagrania z pliku nie pokrywa się z wartościami decybeli z nagrania.

CO ROBIĆ?
Aby udopornić nasz program na szum i na różnicę w poziomie decybeli (która wiadomo że i tak w zależności od mikrofonu i warunków będzie się różniła) Zastosujemy adaptive thresholidng or top-n magnitude peaks. Przy okazji zredukujemy też ilość generowanych haszy przypadających na okno dzięki czemu będziemy w stanie w rozsądnym czasie generować hasze potenajalnie odporne na róznicę decybeli (pod warunkiem że wartości z nagrania mają cokolwiek wspólnego z wartościami z pliku audio, a nie jest to po prostu intensywnie zaszumiona papa). Jeżeli tak jest, to prawdopodobnie będzie znaczyło że nagranie stanowi zaszumioną i nie wartą przetwarzania papę (wtedy rozumiem że najlepszym rozwiązaniem byłoby po prostu przetestować algorytm z recording na identycznej próbce i sprawdzić czy problem nie leży gdzieś w implementacji)

SUGESTIA
W kontekście przetwarzania haszy, jak już zacznie odszukiwać jakieś powiązania, dobrym pomysłem będzie wczytywanie dźwięku jako całości, a nie jako pojedynczego chunka, ponieważ potem trudno nam się będzie odnieść w jakich odstępach czasowych pojawiają się dopasowania.
Proponuję zatem na sztywno wczytanie całego audio (ewentualnie nadanie timera, który wyłączy odsłuchiwanie jeżeli użytkwonik nie zrobi tego ręcznie)

Czat podopowiada że lepszym rozwiązaniem będzie wczytywanie nagrania chunkami zamiast wczytywanie nagrania jako całości (lepsze w kontekście przetwarzania w czasie rzeczywistym i ewentualny podjęciu decyzji szybciej).

Batching jest zalecany w kontekście przetawrzania ciągłego strumienia dźwięku z nagrania.


Po naprawie - usprawienia 
	
	Problem duplikatów haszy:
		Obecnie duplikaty haszy w obrębie chunka są kasowane (NIEZALECANE)
			- duplikaty haszy zwiększają odporność na zaszumienie
			- mniejsza skuteczność dla krótkich, powtarzalnych fragmentów utworu
			- pozbawimy się dodatkowych haszy opisujących dany utwór
		
	Zalecane rozwiązania:
		1) Wyrzucamy duplikaty haszy w obrębie chunka na rzecz innych wartości z top-n
			Też lipa bo najpierw jest szukanie top N na podstawie magnitude, a dopiero potem określa się hasze. Hasze generuje się na podstawie offsetu czasowego a zatem dupa bo trzeba by wykluczać powtarzające się częstotliwości w obrębie chunka (nie wiem czy niezbyt dewastujące dla programu).
		2) Nie wyrzucamy nic (technicznie hasz i tak zapisywany jest raz a dalej to już tylko jego wystąpienia więc ilość zajmowana w pamięci nie jest taka duża) THIS
			powtarzające się wartości hasza w obrębie chunka - do tego timestampy musiałyby mieć swoje unikalne id, ponieważ obecnie klucz obcy zabrania tworzenia identycznych rekordów. 
	Implementacja rozpoznawania utworów prawdopodobnie będzie przebiegała z użyciem SD (Standard Deviation) IQR (Interquantile Range) oraz MAD (Mean Absolute Deviation)
	
	Należy się jednak zastanowić jakie informacje odnośnie hasza będą nam potrzebne do skutecznego przetwarzania (mówimy o haszah pobranych z bazy danych):
		- id piosenki 
		- timestamp (id chunka w piosence w obrębie którego pojawił się hasz)
		
	Dobrym pomysłem może być stworzenie odrębnej której zadaniem będzie przechowywanie pasujących haszy ( w obrębie danego wywołania process chunk ) dla danej piosenki i obliczenie SD oraz MAD. Na podstawie tych dwóch wartości obliczany będzie współczynnik rankingujący utwór (to czy raczej nie to).
	
	Każde chunk processing będzie generowało (w zalezności od ilości dopasowanych piosenek) własny tego typu obiekt klasy, którego zadaniem będzie przechowywanie wartości rankingującej obliczonej w konstruktorze na podstawie listy timestampów oraz id piosenki. Po wyliczeniu wszystkich wartości rankingujących, wybierana jest najkorzystniejsza a jej hasz piosenki jest zapisywany w jako dominujący (Można zrobić w postaci listy, a potem pogrupować w razie gdyby doszło do jakiegoś przechylenia w wartościach w danym chunku)
	
	Obiekt rankingujący powinien przyjmować w konstruktorze listę haszy dla danej piosenki oraz id piosenki, ale nie powinien tej listy zapisywać (bez sensu pamięciowo)
	
	
Plan na jutro (22.01.2025)
	- ustalić co zrobić z powtórkami timestampów (uwzględniamy czy wyrzucamy
	- sprawdzić czy wykrywanie działa (przetestować pod kątem błędów w implementacji oraz błędów generalnie (testowanie w ciężkich warunakch)) DONE
	- sprawdzić czy działa dla innych wersji utworu (niż dostarczony) DONE
	- wywalić niepotrzebny śmietnik, który nie jest w realnym wykorzystaniu (REFACTORING) DONE?
	- Jeżeli pojawi się problem z iterowaniem po zakończeniu nagrywania to rozwiązać
	-* Jak starczy czasu i siły, rozpocząć przerzutkę na .NET MVC Z tym co jest dostępne i przystąpić do tworzenia frontu aplikacji.
	
Fitrowanie haszy nie działa tak jak powinno. Wkrywa nie tak jak trzeba (jak cicho) a już na pewno nie rozpoznaje utworów z innej wersji wykonania niż dostarczona z pliku

Niestety podejście z wykorzystaniem stdDev oraz mad nie działa. Nawet ilościowe zliczanie haszy okazuje się być lepsze niż to rozwiązanie.

Zastosowanie miar statystycznych:
	- dla krótkich nagrań, kiepski match (czasami nie trafia)
	- dla długich raczej nie ma problemu
	- dla piosenki z innej wersji nagrania nie ma szans na matcha

Zastosowanie zliczania haszy
	- dla krótkich nagrań raczej się zgadza
	- dla długich nagrań się zgadza
	- jeżeli nagranie jest długie, match dla utworu z innej wersji nagraniowej
	
	
Nowe podejście: Ustalamy piosenkę na podstawie powtarzającego się offsetu
	1) Dla każdego chunka sprawdzamy znalezione timestampy z bazy danych
	2) Dla każdej piosenki (z timestampów) liczymy offsety czyli różnicę między położeniem w nagraniu a różnicę między położeniem w piosence
	3) Zbieramy (zmiast haszy) wraz z przypisanymi do nich ID piosenki
	4) na koniec sumujemy dla każdej piosenki największą ilość offsetów tego samego rodzaju 
	5) Wygyrwa piosenka o największym, ilościowym dopasowaniu ofsetów

Rozwiązanie z offsetami:
	- zgadza się dla Gone Country i dla Bon Jovi
	- ma problem z rozpoznaniem Smoking Fire (prawdopodobnie piosenka jest bardzo powtarzalna na wskazanym fragmencie przez co zwraca bardzo podobne rezultaty)
	- Chyba rozpoznaje utwór w innej wersji, ale dobrze jak nie ma zbyt dużego zaszumienia
	
Plan na jutro (23.01.2024)
	- stawiamy aplikację na .NET MVC
	- funkcjonalności będą jeszcze dalej testowane na wersji konsolowej aczkolwiek trzeba już przygotować GUI żeby nie zostać w lesie.
	- Generalnie system dopasowywania w jakimś stopniu już działa
	- jego poprawki nie są tak istotne jak przygotowanie GUI
	




	