Naprawa identyfikacji utworów (co wziąć pod uwagę)?

	- Zastanowić się czy przedziały częstotliwości dobrane są prawidłowo (powinny być peaki częstoliwości w obrębie chunka - powinny tworzyć nam hasza dla piosenki).
	x Zmiana Samplowania utworów niestety nic nie dała (dalej nie wykrywa utworów z nagrania)
	- można spróbować zaimplementować rozwiązanie ze spektrogramem zamiast haszowania takiego jakie mam obecnie
	-
	
	
Potencjalne problemy:
	
	Hasze wyraźnie są różne dla dźwięku nagranego i dla dźwięku z mp3
	
	1) Mikrofon nie nagrywa prawidłowo dźwięku
		A Przygotować prosty program do odtworzenia nagranego dźwięku (zobaczyć co faktycznie przychodzi na input) FAILED (aczkolwiek dźwięk jest cichszy)
			Dźwięk wydaje się być odpowiedni aczkolwiek jest dużo cichszy niż dźwięk dostarczony w nagraniu mp3
		
	2) Przetwarzanied dźwięku z mikrofonu odbywa się inczej niż przetwarzanie z mp3 (stąd inne hasze)
		A Ujednolicić formaty dźwięku FAILED
		!B Zmienić metodę tworzenia haszy (np. spektrogramy) (np. rozwiązanie zapropnowane przez czat)
		C Zmniejszyć rozmiar chunka (być może peak dobierany jest na zbyt dużym obszarze stąd ciężko o dobre przypasowanie) (RACZEJ NIE O TO CHODZI)
			Rozmiar chunka wpływa na dokładność, mniejszy chunk to większa dokładnośc czasowa, ale mniejsza dokładność jeśli chodzi o znajdowane peaki.
		D Przeanalizować Proces generowania hasza dla obu przypadków 
		E Zastosować zazebianie się haszy SLIGHTLY BETTER
			Zaimplementowano zazębianie się haszy w stopniu 50%
			Niestety nie ma zbyt dużej poprawy
		
	3) Przedział z którego wybieramy wartości dla hasza nie wystarczająco miarodanjny aby rozpoznać piosenkę
	
	Dla Overlaping 50% bedziemy mieli 2* CHUNK_COUNT  - 1 okienek do ogarnięcia
	

Dziennik
13.01.2025
Jeżeli nie pomoże rozwiązanie ze zazębianiem, należy spróbować rozwiązać generowanie spektrogramami tak jak zalecił to czat.
W ten sposób być może faktycznie nie będzie problemu z różnicą w generowanych haszach
Szczególnie zwrócić uwagę na przedział w którym generowane są hasze (w jaki sposób następuje segregacja które przedziały faktycznie uwzględniamy w haszowaniu)

Warto się też może zastanowić, skoro ograniczamy ilość generowanych haszy, to może by tak generować tylko częstotliwości które wykorzystamy

Dodanie zazębiania się sprawiło że mamy więcej haszy (niemalże dwukrotnie) na piosenkę

Niestety, algorytm dalej praktycznie nie jest w stanie rozpoznać piosenki.

Prawdopodobnie problem leży zakorzeniony w samym algorytmie tworzenia haszy lub wykrywania peaków. KIERUNEK ROZWOJU

Przed przystąpieniem do pracy, zapisać wersję programu na githubie (ogarnąć system kontroli wersji)

TO DO:
	- przeładować nagrania
	- ogarnąć system kontroli wersji
	- spróbować zastosować implementację haszy w oparciu o wskazówki z czata gpt (być może rozwiązanie ze spektrogramami sprawdzi się lepiej przy identyfikacji)
	- zostawić na wszelki wypadek przerobioną, dotychczasową wersję programu jakby trzeba było wrócić do rozwiązania z artykułu.
	- Sprawdzić rezultaty dla tak zorganiozwanego haszowania
	- Jeśli to nie pomoże, szukamy innego rozwiązania tworzenia haszy (przegląd literatury)

PRO TIP
Można znaleźć sobie krótsze dźwięki do identyfikacji żeby trochę krócej się to wszystko przetwarzało (a przynajmniej dopóki nie ogarnę rozsądnego haszowania) DONE

Dziennik 14.01.2025
Szukanie piosenek z tekstem idzie nieco lepiej niż szukanie piosenek z samą melodią, ale i tak wynik jest raczej mizerny RESULT

Przebudować na koniec projektowania wariantu spektrogramowego konstruktury w SongProcessor aby nie było takiego zróżnicowania pomiędzy nagraniem a normalnym dźwiękiem.

Zamiast AudioData lepiej będzie zastosować pole byte[] do przetwarzania

Jeżeli Rozwiązanie ze spektrogramem okaże sie skuteczne, to konieczne będzie szczegółowe doczytanie o oknie, Hamminga, jego zastosowaniu a także czym faktycznie ono jest (znaleźć literaturę do tego)

Okno Hamminga pozwala na oczyszczenie krańców okien z niepotrzebnych zakłóceń (w dużym skrócie)

Rozważyć, w celu zwiększenia wydajności programu, zastosowanie operacji LINQ zamiast pętli (podobnie jak w pythonie redukujemy ręczne iteracje, to nie C)

W podeściu ze spektrogramami (ale chyba nie tylko), domenę czasu wyznaczają nam okna natomiast domenę częstotliwości, poszczególne wartości magnitue w danym oknie.
Generalnie jeśli o to chodzi to spektrogram przechowuje zlogarytmizowane wartości magnitue, które wiemy w jakich momentach czasowych się znajdują dzięki podziałowi na okna.
		

I'm not sure about one thing. What about song sequences which overlaps within a song. If we construct hash based on frequencies and time differences between peaks

Generalnie po zastosowaniu skali logarytminczej sugeruje że większość db to [-40, 0] (poniżej -40 są już dźwięki ciche).
Wartości db mogą sięgać jednak nawet 40 a w Alanie Jacksonie 50db

ROZKMINIĆ DLACZEGO POWTARZAJĄ SIĘ TIMESTAMPY

Generowanie haszy odbywa się nie najgorzej, aczkolwiek jest ich zdecydowanie za dużo. Można pobawić się thresholdem, ale nie dla każdej piosenki będzie to rozwiązanie korzystne.

To do:
	- Spróbować przegenerować dla większego thresholda
	- Spróbować połączyć podejścia z zapisywaniem wartości największych i odległościami między peakami
	- Przepatrzeć dokładnie jeszcze raz kod na czacie i porównać rozwiązania (być może coś mi umknęło lub zostało źle zaimplementowane)
	- Rozwiązać problem zduplikowanych timestampów (dlaczego część wartości jest identyczna) - chyba nie powinno tak być
	- sprawdzić jakie są inne możeliwości (poza tresholdem i min max) żeby otwfiltrować nadmierne hasze i jednocześnie zapewnić sporą dokładność rozpoznawania
		- zaimplementować inny sposób ograniczania liczby haszy na przedział na podstawie wylistowanych metod (wybrać którąś i przetestować)
		Fajne:
			- Top N peaks
			- Frequency band limiting (dzielimy sobie na obszary częstotliwości i na ich podstawie określamy ile maksymalnych wartości chcemy - łączenie z Top n peaks)
			- NMS - sprawdzamy sąsiedztwo i wybieramy tylko peaki w obrębie danego sąsiedztwa
			- adaptive thresholding - dopasowuje peaki na podstawie wartości w chunku a nie na podstawie odgórnie narzuconego thresholdu
	
	Częściowo udało się przegenerować hasze dla pierwszego utworu, należy dostosować nagrywanie pod to i sparawdzić czy znajdowane będą prawidłowo piosenki przy znacząco zwiększonej liczbie haszy.
	
Dziennik 15.01.2025
Spektrogram z chunka z nagrania charakteryzuje się tym, że mamy do czynienia ze znacznie mniejszą ilością. Mimo że dźwięk jest stosunkowo głośno, to ilość decybeli w spektrogramie sięga +- [-100, -50]db.

Dźwięk w uzyskany z nagrania (Blues Saraceno) charakteryzuje się tym że dopiero około 7800 bajata zaczyna coś reprezentować (nie wynosi 0), ale zwykle jest to przeplatane wartościami skrajnymi (około 255, 253 itp.) także zakładam że to może być szum. Pojawiają się również wartości 0-10 (czyli szum z tej drugiej strony)

Od około 8100 bajta piosenka zaczyna się powoli rozkręcać a wartości coraz bardziej zbliżają się do środka przedziału.

Dopiero od 3 chunka można powiedzieć że w wersji przetworzonej z pliku pojawiają się decybele przekraczające 0. W pierwszym i drugim chunku tylko wartości -120db. Dopiero w 3 chunku pojawiają się inne ujemne wartości decybeli ale już nie -120. (Moment w którym rozkręca się piosenka)

W przypadku spektrogramów z nagrania wartości decybeli wahają się od -70 do -50db około

W dalszych częściach utworu wartości wydają się być bardziej zbliżone do 0 a czasami są nawet dodatnie, nie mniej jednak średnia wartości oscyluje zdecydowanie w przedziale -60 do -30db (czyli ujemne).

To tłumaczy dla czego nie są generowane żadne matche (threshold powyżej 20db, a tutaj po prostu prawdopodobnie nie ma takich wartości, albo występują bardzo sporadycznie).

Generalnie zatem wygląda na to że przedział decybeli dla nagrania z pliku nie pokrywa się z wartościami decybeli z nagrania.

CO ROBIĆ?
Aby udopornić nasz program na szum i na różnicę w poziomie decybeli (która wiadomo że i tak w zależności od mikrofonu i warunków będzie się różniła) Zastosujemy adaptive thresholidng or top-n magnitude peaks. Przy okazji zredukujemy też ilość generowanych haszy przypadających na okno dzięki czemu będziemy w stanie w rozsądnym czasie generować hasze potenajalnie odporne na róznicę decybeli (pod warunkiem że wartości z nagrania mają cokolwiek wspólnego z wartościami z pliku audio, a nie jest to po prostu intensywnie zaszumiona papa). Jeżeli tak jest, to prawdopodobnie będzie znaczyło że nagranie stanowi zaszumioną i nie wartą przetwarzania papę (wtedy rozumiem że najlepszym rozwiązaniem byłoby po prostu przetestować algorytm z recording na identycznej próbce i sprawdzić czy problem nie leży gdzieś w implementacji)

SUGESTIA
W kontekście przetwarzania haszy, jak już zacznie odszukiwać jakieś powiązania, dobrym pomysłem będzie wczytywanie dźwięku jako całości, a nie jako pojedynczego chunka, ponieważ potem trudno nam się będzie odnieść w jakich odstępach czasowych pojawiają się dopasowania.
Proponuję zatem na sztywno wczytanie całego audio (ewentualnie nadanie timera, który wyłączy odsłuchiwanie jeżeli użytkwonik nie zrobi tego ręcznie)

Czat podopowiada że lepszym rozwiązaniem będzie wczytywanie nagrania chunkami zamiast wczytywanie nagrania jako całości (lepsze w kontekście przetwarzania w czasie rzeczywistym i ewentualny podjęciu decyzji szybciej).

Batching jest zalecany w kontekście przetawrzania ciągłego strumienia dźwięku z nagrania.